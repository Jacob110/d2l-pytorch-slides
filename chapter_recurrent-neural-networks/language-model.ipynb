{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f537e56",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Language Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0aee1d",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:30.137418Z",
     "iopub.status.busy": "2023-08-18T07:07:30.136666Z",
     "iopub.status.idle": "2023-08-18T07:07:33.007044Z",
     "shell.execute_reply": "2023-08-18T07:07:33.005712Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a160a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read minibatches of input sequences and target sequences at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a328cf",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:33.027839Z",
     "iopub.status.busy": "2023-08-18T07:07:33.027290Z",
     "iopub.status.idle": "2023-08-18T07:07:33.895466Z",
     "shell.execute_reply": "2023-08-18T07:07:33.894547Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[16,  4, 21,  2,  8, 16, 15,  2, 13,  0],\n",
      "        [ 0,  8, 19,  2, 23, 10, 21,  2, 21, 10]]) \n",
      "Y: tensor([[ 4, 21,  2,  8, 16, 15,  2, 13,  0, 21],\n",
      "        [ 8, 19,  2, 23, 10, 21,  2, 21, 10, 16]])\n"
     ]
    }
   ],
   "source": [
    "@d2l.add_to_class(d2l.TimeMachine)  \n",
    "def __init__(self, batch_size, num_steps, num_train=10000, num_val=5000):\n",
    "    super(d2l.TimeMachine, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    corpus, self.vocab = self.build(self._download())\n",
    "    array = torch.tensor([corpus[i:i+num_steps+1]\n",
    "                        for i in range(len(corpus)-num_steps)])\n",
    "    self.X, self.Y = array[:,:-1], array[:,1:]\n",
    "\n",
    "@d2l.add_to_class(d2l.TimeMachine)  \n",
    "def get_dataloader(self, train):\n",
    "    idx = slice(0, self.num_train) if train else slice(\n",
    "        self.num_train, self.num_train + self.num_val)\n",
    "    return self.get_tensorloader([self.X, self.Y], train, idx)\n",
    "\n",
    "data = d2l.TimeMachine(batch_size=2, num_steps=10)\n",
    "for X, Y in data.train_dataloader():\n",
    "    print('X:', X, '\\nY:', Y)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}