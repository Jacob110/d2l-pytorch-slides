{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff08fcd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Linear Algebra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d750626a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:29.444576Z",
     "iopub.status.busy": "2023-08-14T16:39:29.443933Z",
     "iopub.status.idle": "2023-08-14T16:39:31.691486Z",
     "shell.execute_reply": "2023-08-14T16:39:31.690085Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e77075",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Scalars are implemented as tensors \n",
    "that contain only one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5021dcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.697065Z",
     "iopub.status.busy": "2023-08-14T16:39:31.695832Z",
     "iopub.status.idle": "2023-08-14T16:39:31.728603Z",
     "shell.execute_reply": "2023-08-14T16:39:31.727461Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819f1ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can think of a vector as a fixed-length array of scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ecae5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.735393Z",
     "iopub.status.busy": "2023-08-14T16:39:31.734799Z",
     "iopub.status.idle": "2023-08-14T16:39:31.743292Z",
     "shell.execute_reply": "2023-08-14T16:39:31.742251Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1ade4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We access a tensor's elements via indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278d8e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.747492Z",
     "iopub.status.busy": "2023-08-14T16:39:31.747219Z",
     "iopub.status.idle": "2023-08-14T16:39:31.754226Z",
     "shell.execute_reply": "2023-08-14T16:39:31.753300Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55afa4fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In code, this corresponds to the tensor's length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdadab6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.758988Z",
     "iopub.status.busy": "2023-08-14T16:39:31.758633Z",
     "iopub.status.idle": "2023-08-14T16:39:31.764857Z",
     "shell.execute_reply": "2023-08-14T16:39:31.763855Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab421fb7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Tensors with just one axis have shapes with just one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baad1d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.770224Z",
     "iopub.status.busy": "2023-08-14T16:39:31.768359Z",
     "iopub.status.idle": "2023-08-14T16:39:31.776168Z",
     "shell.execute_reply": "2023-08-14T16:39:31.775098Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb542f04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can convert any appropriately sized $m \\times n$ tensor \n",
    "into an $m \\times n$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b6a0ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.785456Z",
     "iopub.status.busy": "2023-08-14T16:39:31.783631Z",
     "iopub.status.idle": "2023-08-14T16:39:31.793567Z",
     "shell.execute_reply": "2023-08-14T16:39:31.792458Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e206a4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Matrix's transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860fdcc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.798013Z",
     "iopub.status.busy": "2023-08-14T16:39:31.796901Z",
     "iopub.status.idle": "2023-08-14T16:39:31.806526Z",
     "shell.execute_reply": "2023-08-14T16:39:31.802450Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f655a04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Symmetric matrices are the subset of square matrices\n",
    "that are equal to their own transposes:\n",
    "$\\mathbf{A} = \\mathbf{A}^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3fdf59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.810331Z",
     "iopub.status.busy": "2023-08-14T16:39:31.809741Z",
     "iopub.status.idle": "2023-08-14T16:39:31.818779Z",
     "shell.execute_reply": "2023-08-14T16:39:31.817842Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2559932",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tensors\n",
    "give us a generic way of describing \n",
    "extensions to $n^{\\textrm{th}}$-order arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e6adf12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.824961Z",
     "iopub.status.busy": "2023-08-14T16:39:31.822688Z",
     "iopub.status.idle": "2023-08-14T16:39:31.838067Z",
     "shell.execute_reply": "2023-08-14T16:39:31.837069Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84da0336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.844017Z",
     "iopub.status.busy": "2023-08-14T16:39:31.841991Z",
     "iopub.status.idle": "2023-08-14T16:39:31.853849Z",
     "shell.execute_reply": "2023-08-14T16:39:31.850834Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812d967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Elementwise product of two matrices\n",
    "is called their *Hadamard product*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd98239d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.859681Z",
     "iopub.status.busy": "2023-08-14T16:39:31.859337Z",
     "iopub.status.idle": "2023-08-14T16:39:31.865836Z",
     "shell.execute_reply": "2023-08-14T16:39:31.864832Z"
    },
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f58d7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adding or multiplying a scalar and a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9375f4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.871959Z",
     "iopub.status.busy": "2023-08-14T16:39:31.871617Z",
     "iopub.status.idle": "2023-08-14T16:39:31.886051Z",
     "shell.execute_reply": "2023-08-14T16:39:31.885027Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c35a61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The sum of a tensor's elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dea02d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.889753Z",
     "iopub.status.busy": "2023-08-14T16:39:31.889158Z",
     "iopub.status.idle": "2023-08-14T16:39:31.897968Z",
     "shell.execute_reply": "2023-08-14T16:39:31.896746Z"
    },
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor(3.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc84c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sums over the elements of tensors of arbitrary shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c4af93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.901974Z",
     "iopub.status.busy": "2023-08-14T16:39:31.901082Z",
     "iopub.status.idle": "2023-08-14T16:39:31.908180Z",
     "shell.execute_reply": "2023-08-14T16:39:31.906852Z"
    },
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), tensor(15.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449836d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Specify the axes \n",
    "along which the tensor should be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f399eef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.912696Z",
     "iopub.status.busy": "2023-08-14T16:39:31.911653Z",
     "iopub.status.idle": "2023-08-14T16:39:31.921559Z",
     "shell.execute_reply": "2023-08-14T16:39:31.918395Z"
    },
    "origin_pos": 61,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c3029d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.925917Z",
     "iopub.status.busy": "2023-08-14T16:39:31.925495Z",
     "iopub.status.idle": "2023-08-14T16:39:31.935242Z",
     "shell.execute_reply": "2023-08-14T16:39:31.934152Z"
    },
    "origin_pos": 64,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b738a92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.938755Z",
     "iopub.status.busy": "2023-08-14T16:39:31.938480Z",
     "iopub.status.idle": "2023-08-14T16:39:31.945330Z",
     "shell.execute_reply": "2023-08-14T16:39:31.944449Z"
    },
    "origin_pos": 67,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a251f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A related quantity is the *mean*, also called the *average*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "136f362e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.949148Z",
     "iopub.status.busy": "2023-08-14T16:39:31.948574Z",
     "iopub.status.idle": "2023-08-14T16:39:31.957945Z",
     "shell.execute_reply": "2023-08-14T16:39:31.956978Z"
    },
    "origin_pos": 71,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2fa2768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.961768Z",
     "iopub.status.busy": "2023-08-14T16:39:31.961426Z",
     "iopub.status.idle": "2023-08-14T16:39:31.970029Z",
     "shell.execute_reply": "2023-08-14T16:39:31.968812Z"
    },
    "origin_pos": 74,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87a7ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keep the number of axes unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dd4738a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.976025Z",
     "iopub.status.busy": "2023-08-14T16:39:31.975182Z",
     "iopub.status.idle": "2023-08-14T16:39:31.984719Z",
     "shell.execute_reply": "2023-08-14T16:39:31.982815Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b0ac15",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Divide `A` by `sum_A` with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4336bfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:31.992033Z",
     "iopub.status.busy": "2023-08-14T16:39:31.990883Z",
     "iopub.status.idle": "2023-08-14T16:39:32.001155Z",
     "shell.execute_reply": "2023-08-14T16:39:32.000113Z"
    },
    "origin_pos": 80,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96274b08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cumulative sum of elements of `A` along some axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "448bdb29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.008151Z",
     "iopub.status.busy": "2023-08-14T16:39:32.005269Z",
     "iopub.status.idle": "2023-08-14T16:39:32.014629Z",
     "shell.execute_reply": "2023-08-14T16:39:32.013511Z"
    },
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d99a74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *dot product* of two vectors is a sum over the products of the elements at the same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "001eccf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.018311Z",
     "iopub.status.busy": "2023-08-14T16:39:32.018015Z",
     "iopub.status.idle": "2023-08-14T16:39:32.029176Z",
     "shell.execute_reply": "2023-08-14T16:39:32.028254Z"
    },
    "origin_pos": 86,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12287c8f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can calculate the dot product of two vectors \n",
    "by performing an elementwise multiplication followed by a sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e134cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.035709Z",
     "iopub.status.busy": "2023-08-14T16:39:32.034832Z",
     "iopub.status.idle": "2023-08-14T16:39:32.048245Z",
     "shell.execute_reply": "2023-08-14T16:39:32.047212Z"
    },
    "origin_pos": 91,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd93e91c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The matrix--vector product $\\mathbf{A}\\mathbf{x}$\n",
    "is simply a column vector of length $m$,\n",
    "whose $i^\\textrm{th}$ element is the dot product \n",
    "$\\mathbf{a}^\\top_i \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d3c75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.055057Z",
     "iopub.status.busy": "2023-08-14T16:39:32.052305Z",
     "iopub.status.idle": "2023-08-14T16:39:32.063283Z",
     "shell.execute_reply": "2023-08-14T16:39:32.062303Z"
    },
    "origin_pos": 99,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), tensor([ 5., 14.]), tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x), A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa625275",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can think of the matrix--matrix multiplication $\\mathbf{AB}$\n",
    "as performing $m$ matrix--vector products \n",
    "or $m \\times n$ dot products \n",
    "and stitching the results together \n",
    "to form an $n \\times m$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29dc7a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.069050Z",
     "iopub.status.busy": "2023-08-14T16:39:32.068287Z",
     "iopub.status.idle": "2023-08-14T16:39:32.080627Z",
     "shell.execute_reply": "2023-08-14T16:39:32.077964Z"
    },
    "origin_pos": 104,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3, 4)\n",
    "torch.mm(A, B), A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a02ce5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\ell_2$ *norm*\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27aa05bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.086847Z",
     "iopub.status.busy": "2023-08-14T16:39:32.084610Z",
     "iopub.status.idle": "2023-08-14T16:39:32.096589Z",
     "shell.execute_reply": "2023-08-14T16:39:32.095463Z"
    },
    "origin_pos": 109,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e70c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\ell_1$ norm\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1117ae11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.101131Z",
     "iopub.status.busy": "2023-08-14T16:39:32.100390Z",
     "iopub.status.idle": "2023-08-14T16:39:32.108721Z",
     "shell.execute_reply": "2023-08-14T16:39:32.107670Z"
    },
    "origin_pos": 114,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dcae7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *Frobenius norm*, \n",
    "which is much easier to compute\n",
    "$$\\|\\mathbf{X}\\|_\\textrm{F} = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eac0ae99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T16:39:32.112924Z",
     "iopub.status.busy": "2023-08-14T16:39:32.111939Z",
     "iopub.status.idle": "2023-08-14T16:39:32.120200Z",
     "shell.execute_reply": "2023-08-14T16:39:32.119151Z"
    },
    "origin_pos": 119,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}