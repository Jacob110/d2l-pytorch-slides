{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405b943e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Linear Algebra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a55056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:03.693362Z",
     "iopub.status.busy": "2023-08-18T07:07:03.692609Z",
     "iopub.status.idle": "2023-08-18T07:07:05.353414Z",
     "shell.execute_reply": "2023-08-18T07:07:05.352483Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fcd4e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Scalars are implemented as tensors \n",
    "that contain only one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c813ca63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.357696Z",
     "iopub.status.busy": "2023-08-18T07:07:05.356875Z",
     "iopub.status.idle": "2023-08-18T07:07:05.386036Z",
     "shell.execute_reply": "2023-08-18T07:07:05.385277Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351228d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can think of a vector as a fixed-length array of scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc1682f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.389281Z",
     "iopub.status.busy": "2023-08-18T07:07:05.388779Z",
     "iopub.status.idle": "2023-08-18T07:07:05.394259Z",
     "shell.execute_reply": "2023-08-18T07:07:05.393518Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab35395",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We access a tensor's elements via indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4940d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.398194Z",
     "iopub.status.busy": "2023-08-18T07:07:05.397550Z",
     "iopub.status.idle": "2023-08-18T07:07:05.402747Z",
     "shell.execute_reply": "2023-08-18T07:07:05.401986Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d8edf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In code, this corresponds to the tensor's length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99239f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.407165Z",
     "iopub.status.busy": "2023-08-18T07:07:05.406540Z",
     "iopub.status.idle": "2023-08-18T07:07:05.411386Z",
     "shell.execute_reply": "2023-08-18T07:07:05.410629Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef80dda",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Tensors with just one axis have shapes with just one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c045e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.415845Z",
     "iopub.status.busy": "2023-08-18T07:07:05.415414Z",
     "iopub.status.idle": "2023-08-18T07:07:05.420211Z",
     "shell.execute_reply": "2023-08-18T07:07:05.419469Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf9213",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can convert any appropriately sized $m \\times n$ tensor \n",
    "into an $m \\times n$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbe9555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.424791Z",
     "iopub.status.busy": "2023-08-18T07:07:05.424273Z",
     "iopub.status.idle": "2023-08-18T07:07:05.429812Z",
     "shell.execute_reply": "2023-08-18T07:07:05.429029Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600651b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Matrix's transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb0270c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.434228Z",
     "iopub.status.busy": "2023-08-18T07:07:05.433572Z",
     "iopub.status.idle": "2023-08-18T07:07:05.438778Z",
     "shell.execute_reply": "2023-08-18T07:07:05.438036Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b5030",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Symmetric matrices are the subset of square matrices\n",
    "that are equal to their own transposes:\n",
    "$\\mathbf{A} = \\mathbf{A}^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd21b0cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.443139Z",
     "iopub.status.busy": "2023-08-18T07:07:05.442511Z",
     "iopub.status.idle": "2023-08-18T07:07:05.448318Z",
     "shell.execute_reply": "2023-08-18T07:07:05.447573Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b636b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tensors\n",
    "give us a generic way of describing \n",
    "extensions to $n^{\\textrm{th}}$-order arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacc4dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.452685Z",
     "iopub.status.busy": "2023-08-18T07:07:05.452062Z",
     "iopub.status.idle": "2023-08-18T07:07:05.457733Z",
     "shell.execute_reply": "2023-08-18T07:07:05.456933Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf224058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.462093Z",
     "iopub.status.busy": "2023-08-18T07:07:05.461529Z",
     "iopub.status.idle": "2023-08-18T07:07:05.468138Z",
     "shell.execute_reply": "2023-08-18T07:07:05.467373Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bbe72b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Elementwise product of two matrices\n",
    "is called their *Hadamard product*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91228673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.471572Z",
     "iopub.status.busy": "2023-08-18T07:07:05.470992Z",
     "iopub.status.idle": "2023-08-18T07:07:05.476519Z",
     "shell.execute_reply": "2023-08-18T07:07:05.475755Z"
    },
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c7fd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adding or multiplying a scalar and a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5485de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.480759Z",
     "iopub.status.busy": "2023-08-18T07:07:05.480196Z",
     "iopub.status.idle": "2023-08-18T07:07:05.486149Z",
     "shell.execute_reply": "2023-08-18T07:07:05.485375Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60b057",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The sum of a tensor's elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "657411da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.489522Z",
     "iopub.status.busy": "2023-08-18T07:07:05.488953Z",
     "iopub.status.idle": "2023-08-18T07:07:05.494997Z",
     "shell.execute_reply": "2023-08-18T07:07:05.494249Z"
    },
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor(3.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70af08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sums over the elements of tensors of arbitrary shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab220f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.498418Z",
     "iopub.status.busy": "2023-08-18T07:07:05.497761Z",
     "iopub.status.idle": "2023-08-18T07:07:05.503273Z",
     "shell.execute_reply": "2023-08-18T07:07:05.502518Z"
    },
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), tensor(15.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980c807",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Specify the axes \n",
    "along which the tensor should be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e46544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.506555Z",
     "iopub.status.busy": "2023-08-18T07:07:05.506026Z",
     "iopub.status.idle": "2023-08-18T07:07:05.511121Z",
     "shell.execute_reply": "2023-08-18T07:07:05.510375Z"
    },
    "origin_pos": 61,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7d134d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.514577Z",
     "iopub.status.busy": "2023-08-18T07:07:05.513946Z",
     "iopub.status.idle": "2023-08-18T07:07:05.519091Z",
     "shell.execute_reply": "2023-08-18T07:07:05.518345Z"
    },
    "origin_pos": 64,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9e810b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.522522Z",
     "iopub.status.busy": "2023-08-18T07:07:05.521887Z",
     "iopub.status.idle": "2023-08-18T07:07:05.527438Z",
     "shell.execute_reply": "2023-08-18T07:07:05.526694Z"
    },
    "origin_pos": 67,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6c743",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A related quantity is the *mean*, also called the *average*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d94df2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.530860Z",
     "iopub.status.busy": "2023-08-18T07:07:05.530220Z",
     "iopub.status.idle": "2023-08-18T07:07:05.536205Z",
     "shell.execute_reply": "2023-08-18T07:07:05.535384Z"
    },
    "origin_pos": 71,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2111c1bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.539550Z",
     "iopub.status.busy": "2023-08-18T07:07:05.539275Z",
     "iopub.status.idle": "2023-08-18T07:07:05.545503Z",
     "shell.execute_reply": "2023-08-18T07:07:05.544682Z"
    },
    "origin_pos": 74,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895316d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keep the number of axes unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9e3a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.548878Z",
     "iopub.status.busy": "2023-08-18T07:07:05.548241Z",
     "iopub.status.idle": "2023-08-18T07:07:05.553985Z",
     "shell.execute_reply": "2023-08-18T07:07:05.553210Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977dd08",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Divide `A` by `sum_A` with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49ed5d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.557393Z",
     "iopub.status.busy": "2023-08-18T07:07:05.556721Z",
     "iopub.status.idle": "2023-08-18T07:07:05.562073Z",
     "shell.execute_reply": "2023-08-18T07:07:05.561287Z"
    },
    "origin_pos": 80,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf87fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cumulative sum of elements of `A` along some axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e68ddc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.565352Z",
     "iopub.status.busy": "2023-08-18T07:07:05.564832Z",
     "iopub.status.idle": "2023-08-18T07:07:05.570322Z",
     "shell.execute_reply": "2023-08-18T07:07:05.569546Z"
    },
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86192c42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *dot product* of two vectors is a sum over the products of the elements at the same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26e79446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.573560Z",
     "iopub.status.busy": "2023-08-18T07:07:05.573283Z",
     "iopub.status.idle": "2023-08-18T07:07:05.582127Z",
     "shell.execute_reply": "2023-08-18T07:07:05.581321Z"
    },
    "origin_pos": 86,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5920b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can calculate the dot product of two vectors \n",
    "by performing an elementwise multiplication followed by a sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a67e29df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.585355Z",
     "iopub.status.busy": "2023-08-18T07:07:05.585043Z",
     "iopub.status.idle": "2023-08-18T07:07:05.590945Z",
     "shell.execute_reply": "2023-08-18T07:07:05.590189Z"
    },
    "origin_pos": 91,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab91733",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The matrix--vector product $\\mathbf{A}\\mathbf{x}$\n",
    "is simply a column vector of length $m$,\n",
    "whose $i^\\textrm{th}$ element is the dot product \n",
    "$\\mathbf{a}^\\top_i \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bebfbbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.594033Z",
     "iopub.status.busy": "2023-08-18T07:07:05.593759Z",
     "iopub.status.idle": "2023-08-18T07:07:05.600067Z",
     "shell.execute_reply": "2023-08-18T07:07:05.599309Z"
    },
    "origin_pos": 99,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), tensor([ 5., 14.]), tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x), A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7625794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can think of the matrix--matrix multiplication $\\mathbf{AB}$\n",
    "as performing $m$ matrix--vector products \n",
    "or $m \\times n$ dot products \n",
    "and stitching the results together \n",
    "to form an $n \\times m$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ab5bea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.603214Z",
     "iopub.status.busy": "2023-08-18T07:07:05.602937Z",
     "iopub.status.idle": "2023-08-18T07:07:05.609431Z",
     "shell.execute_reply": "2023-08-18T07:07:05.608644Z"
    },
    "origin_pos": 104,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3, 4)\n",
    "torch.mm(A, B), A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55638d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\ell_2$ *norm*\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0502e31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.612581Z",
     "iopub.status.busy": "2023-08-18T07:07:05.612307Z",
     "iopub.status.idle": "2023-08-18T07:07:05.618208Z",
     "shell.execute_reply": "2023-08-18T07:07:05.617467Z"
    },
    "origin_pos": 109,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcdc219",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\ell_1$ norm\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe017fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.621348Z",
     "iopub.status.busy": "2023-08-18T07:07:05.621017Z",
     "iopub.status.idle": "2023-08-18T07:07:05.626672Z",
     "shell.execute_reply": "2023-08-18T07:07:05.625911Z"
    },
    "origin_pos": 114,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4cee1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *Frobenius norm*, \n",
    "which is much easier to compute\n",
    "$$\\|\\mathbf{X}\\|_\\textrm{F} = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2946180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:05.629682Z",
     "iopub.status.busy": "2023-08-18T07:07:05.629410Z",
     "iopub.status.idle": "2023-08-18T07:07:05.635088Z",
     "shell.execute_reply": "2023-08-18T07:07:05.634337Z"
    },
    "origin_pos": 119,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}